<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Low-Light Image Enhancement with Multi-stage Residue Quantization and Brightness-aware Attention</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="../../assets/img/favicon.png" rel="icon">
  <link href="../../assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Roboto:300,300i,400,400i,500,500i,700,700i&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="../../assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="../../assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="../../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="../../assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="../../assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="../../assets/css/style.css" rel="stylesheet">
  <link href="../../assets/css/image_slider.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Moderna - v4.10.1
  * Template URL: https://bootstrapmade.com/free-bootstrap-template-corporate-moderna/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top d-flex align-items-center ">
    <div class="container d-flex justify-content-between align-items-center">

      <div class="logo">
        <h1 class="text-light"><a href="../../index.html"><span>VRL Lab</span></a></h1>
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav id="navbar" class="navbar">
        <ul>
            <li><a class="" href="../../index.html">Home</a></li>
            <li><a href="../../research.html">Research</a></li>
            <li><a class="active" href="../../publication.html">Publication</a></li>
            <li><a href="../../team.html">Team</a></li>
            <li><a href="../../demo.html">Demo</a></li>
            <li><a href="../../contact.html">Join Us</a></li>
          </li>

        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Blog Section ======= -->
    <section class="breadcrumbs">
      <div class="container">
        <div class="d-flex justify-content-between align-items-center">
          <ol>
            <li><a href="../../index.html">Home</a></li>
            <li><a href="../../research.html">Research</a></li>
            <li>Low-Light Image Enhancement with Multi-stage Residue Quantization and Brightness-aware Attention</li>
          </ol>
        </div>

      </div>
    </section><!-- End Blog Section -->

    <!-- ======= Blog Single Section ======= -->
    <section id="blog" class="blog">
      <div class="container" data-aos="fade-up">
        
        <h2>Project</h2>
            <article class="entry entry-single">

                <h1 class="entry-title">
                    <a href="./index.html">Low-Light Image Enhancement with Multi-stage Residue Quantization and Brightness-aware Attention</a>
                </h1>

                <h5><li class="d-flex align-items-center"><i class="bi bi-person"></i> Qian Ning, Fangfang Wu, Weisheng Dong, Xin Li and Guangming Shi</li></h5>

                <!-- <div class="a">
                    <div class="b" id="b">
                        <div><img src="./HR/img_014.png" alt="Before"></div>
                    </div>
                    <img src="./LR/img_014_LR.png" alt="After">
                    <input type="range" id="range" value="50">
                </div> -->

                <img src="./img/network.png" class="img-fluid" alt="">
                <p>
                  Figure 1. Architecture of the proposed network RQ-LLIE for low-light image enhancement (LLIE). Left: The architecture of the overall network.
                  Right (a): The structure of the Basic block in the left figure. Right (b): The structure of the Brightness-aware attention in the left figure.
                </p>

                <div class="entry-content">
                    <h3>Abstract</h3>
                    <p>
                    &emsp;Low-light image enhancement (LLIE) aims to recover il-
                    lumination and improve the visibility of low-light images.
                    Conventional LLIE methods often produce poor results be-
                    cause they neglect the effect of noise interference. Deep
                    learning-based LLIE methods focus on learning a map-
                    ping function between low-light images and normal-light
                    images that outperforms conventional LLIE methods. How-
                    ever, most deep learning-based LLIE methods cannot yet
                    fully exploit the guidance of auxiliary priors provided by
                    normal-light images in the training dataset. In this paper,
                    we propose a brightness-aware network with normal-light 
                    priors based on brightness-aware attention and residual-
                    quantized codebook. To achieve a more natural and re-
                    alistic enhancement, we design a query module to obtain
                    more reliable normal-light features and fuse them with low-
                    light features by a fusion branch. In addition, we propose
                    a brightness-aware attention module to further improve the
                    robustness of the network to the brightness. Extensive ex-
                    perimental results on both real-captured and synthetic data
                    show that our method outperforms existing state-of-the-art
                    methods.
                    </p>

                    <h3>Paper & Code & Demo</h3>
                    <ul>
                        <p>
                            <i class="bi bi-check"></i> <a href="https://see.xidian.edu.cn/faculty/wsdong/Papers/Conference/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.pdf">Paper</a>
                        </p>
                        <p>
                            <i class="bi bi-check"></i> <a href="https://github.com/LiuYunlong99/RQ-LLIE">Code</a>
                        </p>
                        <!-- <p>
                            <i class="bi bi-check"></i> <a href="https://github.com/Fangzhenxuan/UncertaintySR">Demo</a>
                        </p> -->
                    </ul>
                    
                    <h3>Experimental Results</h3>
                    <ul>
                        <p>
                          Table 1. Quantitative comparison on the LOLv1 dataset.
                        </p>
                        <img src="./img/table_1.png" class="img-fluid" alt="">

                        <p>
                          Table 2. Quantitative comparison on the LOLv2-Real and LOLv2-Synthetic dataset. 
                        </p>
                        <img src="./img/table_2.png" class="img-fluid" alt="">

                    </ul>

                    <h3>Result Visualization</h3>
                    <ul>
                        <img src="./img/fig_1.png" class="img-fluid" alt="">
                        <p>
                          Figure 1: Visual quality comparisons of different low-light image enhancement methods on the LOLv1 dataset.
                        </p>
                        <img src="./img/fig_2.png" class="img-fluid" alt="">
                        <p>
                          Figure 2: Visual quality comparisons of different low-light image enhancement methods on the LOLv2-Real dataset.
                        </p>
                        <img src="./img/fig_3.png" class="img-fluid" alt="">
                        <p>
                          Figure 3: Visual quality comparisons of different low-light image enhancement methods on the LOLv2-Synthetic dataset.
                        </p>
                    </ul>

                    <h3>Citation</h3>
                    <p>
                        @InProceedings{Liu_2023_ICCV,<br>
                          &emsp;author    = {Liu, Yunlong and Huang, Tao and Dong, Weisheng and Wu, Fangfang and Li, Xin and Shi, Guangming},<br>
                          &emsp;title     = {Low-Light Image Enhancement with Multi-Stage Residue Quantization and Brightness-Aware Attention},<br>
                          &emsp;booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},<br>
                          &emsp;month     = {October},<br>
                          &emsp;year      = {2023},<br>
                          &emsp;pages     = {12140-12149}<br>
                        }

                    </p>
                    
                    <h3>Concat</h3>
                    <p>
                        <strong>Yunlong Liu</strong>, Email: liuyunlong@stu.xidian.edu.cn <br>
                        <strong>Tao Huang</strong>, Email: thuang_666@stu.xidian.edu.cn <br>
                        <strong>Weisheng Dong</strong>, Email: wsdong@mail.xidian.edu.cn <br>
                        <strong>Fangfang Wu</strong>, Email: wufangfang@xidian.edu.cn <br>
                        <strong>Xin Li</strong>, Email: xli48@albany.edu <br>
                        <strong>Guangming Shi</strong>, Email: gmshi xidian@163.com <br>
                    </p>
                  
                </div>
            </article><!-- End blog entry -->


      </div>
    </section><!-- End Blog Single Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer" data-aos="fade-up" data-aos-easing="ease-in-out" data-aos-duration="500">

    <div class="footer-top">
      <div class="container">
        <div class="row">
          <div class="col-lg-3 col-md-6 footer-contact">
            <h4>Contact Us</h4>
            <p>
              School of Artificial Intelligence <br>
              Xidian University <br>
              8 Taibai South Road, Xi 'an, China<br>
            </p>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="copyright">
        &copy;<span>VRL Lab@XDU, 2023</span></strong>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="../../assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="../../assets/vendor/aos/aos.js"></script>
  <script src="../../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="../../assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="../../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="../../assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="../../assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="../../assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="../../assets/js/main.js"></script>
  <script src="../../assets/js/image_slider.js"></script>

</body>

</html>