<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Memory Based Temporal Fusion Network for Video Deblurring</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="../../assets/img/favicon.png" rel="icon">
  <link href="../../assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Roboto:300,300i,400,400i,500,500i,700,700i&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="../../assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="../../assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="../../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="../../assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="../../assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="../../assets/css/style.css" rel="stylesheet">
  <link href="../../assets/css/image_slider.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Moderna - v4.10.1
  * Template URL: https://bootstrapmade.com/free-bootstrap-template-corporate-moderna/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top d-flex align-items-center ">
    <div class="container d-flex justify-content-between align-items-center">

      <div class="logo">
        <h1 class="text-light"><a href="../../index.html"><span>VRL Lab</span></a></h1>
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav id="navbar" class="navbar">
        <ul>
            <li><a class="" href="../../index.html">Home</a></li>
            <li><a href="../../research.html">Research</a></li>
            <li><a class="active" href="../../publication.html">Publication</a></li>
            <li><a href="../../team.html">Team</a></li>
            <li><a href="../../demo.html">Demo</a></li>
            <li><a href="../../contact.html">Join Us</a></li>
          </li>

        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Blog Section ======= -->
    <section class="breadcrumbs">
      <div class="container">
        <div class="d-flex justify-content-between align-items-center">
          <ol>
            <li><a href="../../index.html">Home</a></li>
            <li><a href="../../research.html">Research</a></li>
            <li>Memory Based Temporal Fusion Network for Video Deblurring</li>
          </ol>
        </div>

      </div>
    </section><!-- End Blog Section -->

    <!-- ======= Blog Single Section ======= -->
    <section id="blog" class="blog">
      <div class="container" data-aos="fade-up">
        
        <h2>Project</h2>
            <article class="entry entry-single">

                <h1 class="entry-title">
                    <a href="./index.html">Memory Based Temporal Fusion Network for Video Deblurring</a>
                </h1>

                <h5><li class="d-flex align-items-center"><i class="bi bi-person"></i> Chaohua Wang, Weisheng Dong, Xin Li, Fangfang Wu, Jinjian Wu and Guangming Shi</li></h5>

                <!-- <div class="a">
                    <div class="b" id="b">
                        <div><img src="./img/network.png" alt="Before"></div>
                    </div>
                    <img src="./LR/img_014_LR.png" alt="After">
                    <input type="range" id="range" value="50">
                </div> -->

                <img src="./img/network.png" class="img-fluid" alt="">
                <p>
                  Figure 1. Architecture of the proposed network TFNet for video deblurring.
                  (a) The architecture of the proposed network. (b) The architecture of the encoder. 
                  (c) The architecture of the temporal fusion module. (d) The detailed architecture of our local spatial-temporal memory based temporal fusion module.
                </p>

                <div class="entry-content">
                    <h3>Abstract</h3>
                    <p>
                    &emsp;Video deblurring is one of the most challenging vision tasks because of the complex spatial-temporal relationship and a
                    number of uncertainty factors involved in video acquisition. As different moving objects in the video exhibit different motion
                    trajectories, it is difficult to accurately capture their spatial-temporal relationships. In this paper, we proposed a memory-based
                    temporal fusion network (TFN) to capture local spatial-temporal relationships across the input sequence for video deblurring.
                    Our temporal fusion network consists of a memory network and a temporal fusion block. The memory network stores the
                    extracted spatial-temporal relationships and guides the temporal fusion blocks to extract local spatial-temporal relationships
                    more accurately. In addition, in order to enable our model to more effectively fuse the multiscale features of the previous
                    frame, we propose a multiscale and multi-hop reconstruction memory network (RMN) based on the attention mechanism and
                    memory network. We constructed a feature extractor that integrates residual dense blocks with three downsample layers to
                    extract hierarchical spatial features. Finally, we feed these aggregated local features into a reconstruction module to restore
                    sharp video frames. Experimental results on public datasets show that our temporal fusion network has achieved a significant
                    performance improvement in terms of PSNR metrics (over 1dB) over existing state-of-the-art video deblurring methods.
                  </p>

                    <h3>Paper & Code & Demo</h3>
                    <ul>
                        <p>
                            <i class="bi bi-check"></i> <a href="https://see.xidian.edu.cn/faculty/wsdong/Papers/Journal/Video_deblurring_IJCV2023.pdf">Paper</a>
                        </p>
                        <p>
                            <i class="bi bi-check"></i> <a href="https://github.com/fengzhuziA/TFmodel">Code</a>
                        </p>
                        <!-- <p>
                            <i class="bi bi-check"></i> <a href="https://github.com/Fangzhenxuan/UncertaintySR">Demo</a>
                        </p> -->
                    </ul>
                    
                    <h3>Experimental Results</h3>
                    <ul>
                        <p>
                          Table 1 and Table 2 . The quantitative results on GOPRO and BSD dataset.
                        </p>
                        <img src="./img/table.png" class="img-fluid" alt="">
                    </ul>

                    <h3>Result Visualization</h3>
                    <ul>
                        <img src="./img/fig_1.png" class="img-fluid" alt="">
                        <p>
                          Figure 1. Visualizations of attention maps. (a) The input blurred frames. (b) Deblurred frames by the proposed method. (c) The ground truth frames. (d) Attention maps of the middle frame in adjacent frames.

                        </p>
                        <img src="./img/fig_2.png" class="img-fluid" alt="">
                        <p>
                          Figure 2. The figure shows the two video clips A and B with the lowest and highest PSNR scores in the GOPRO dataset.
                        </p>
                    </ul>

                    <h3>Citation</h3>
                    <p>
                        @article{wang2023memory,<br>
                          &emsp;title={Memory Based Temporal Fusion Network for Video Deblurring},<br>
                          &emsp;author={Wang, Chaohua and Dong, Weisheng and Li, Xin and Wu, Fangfang and Wu, Jinjian and Shi, Guangming},<br>
                          &emsp;journal={International Journal of Computer Vision},<br>
                          &emsp;pages={1--17},<br>
                          &emsp;year={2023},<br>
                          &emsp;publisher={Springer}<br>
                        }

                    </p>
                    
                    <h3>Concat</h3>
                    <p>
                        <strong>Chaohua Wang</strong>, Email: 3267928656@qq.com <br>
                        <strong>Weisheng Dong</strong>, Email: wsdong@mail.xidian.edu.cn <br>
                        <strong>Xin Li</strong>, Email: xin.li@mail.wvu.edu <br>
                        <strong>Fangfang Wu</strong>, Email: wufangfang@xidian.edu.cn <br>
                        <strong>Jinjian Wu</strong>, Email: jinjian.wu@mail.xidian.edu.cn <br>
                        <strong>Guangming Shi</strong>, Email: gmshi@xidian.edu.cn <br>
                    </p>
                  
                </div>
            </article><!-- End blog entry -->


      </div>
    </section><!-- End Blog Single Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer" data-aos="fade-up" data-aos-easing="ease-in-out" data-aos-duration="500">

    <div class="footer-top">
      <div class="container">
        <div class="row">
          <div class="col-lg-3 col-md-6 footer-contact">
            <h4>Contact Us</h4>
            <p>
              School of Artificial Intelligence <br>
              Xidian University <br>
              8 Taibai South Road, Xi 'an, China<br>
            </p>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="copyright">
        &copy;<span>VRL Lab@XDU, 2023</span></strong>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="../../assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="../../assets/vendor/aos/aos.js"></script>
  <script src="../../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="../../assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="../../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="../../assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="../../assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="../../assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="../../assets/js/main.js"></script>
  <script src="../../assets/js/image_slider.js"></script>

</body>

</html>